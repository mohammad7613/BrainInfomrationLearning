{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = os.path.join('D:\\Mastersharif\\MasterProject\\data\\parkinsons-oddball','participants.tsv')\n",
    "# Linux path\n",
    "file_name = os.path.join(\n",
    "    '/mnt/D/Mastersharif/MasterProject/data/parkinsons-oddball', 'participants.tsv')\n",
    "\n",
    "df_participants = pd.read_csv(file_name, delimiter='\\t')\n",
    "\n",
    "\n",
    "path_datasets = ''\n",
    "all_number_task = 75\n",
    "# tasks = {'local_file_path': np.array([]),\n",
    "#         'raw_data_file_name':np.array([]),\n",
    "#         'preprocessed_one':np.array([]),'flag1':np.zeros(all_number_task,),\n",
    "#         'ERP_mat_file':np.array([]),'flag2':np.zeros(all_number_task,),\n",
    "#         'PAC_dist':np.array([]),'flag3':np.zeros(all_number_task,),\n",
    "#         'PAC_dist_mean_channel':np.array([]),'flag4':np.zeros(all_number_task,)}\n",
    "# tasks = {'local_file_path': np.array([]),\n",
    "#          'raw_data_file_name': np.array([]),\n",
    "#          # 'preprocessed_one':np.array([]),\n",
    "#          'preprocessed_two': np.array([]),\n",
    "#          'ERP_mat_file': np.array([]),\n",
    "#          'ERP_npy_file': np.array([]),\n",
    "#          'ERP_npy_file_with_normalization_and_baseline_correction': np.array([]),\n",
    "#          'ERP_nobaseline_npy_file': np.array([]),\n",
    "#          'PAC_sequences_v1': np.array([]),\n",
    "#          'Cavanagh_habituation_signals':np.array([]),\n",
    "#          'Group_file_type': np.array([])}\n",
    "\n",
    "tasks = {'local_file_path': np.array([]),\n",
    "         'raw_data_file_name': np.array([]),\n",
    "         # 'preprocessed_one':np.array([]),\n",
    "         'preprocessed_two': np.array([]),\n",
    "         'ERP_mat_file': np.array([]),\n",
    "         'ERP_npy_file': np.array([]),\n",
    "         'ERP_npy_file_with_normalization_and_baseline_correction': np.array([]),\n",
    "         'ERP_nobaseline_npy_file': np.array([]),\n",
    "         'Cavanagh_habituation_signals': np.array([]),\n",
    "         'Limpel_Ziv_over_channels': np.array([]),\n",
    "         'P300_over_all_channels_without_normalization': np.array([]),\n",
    "         'Group_file_type': np.array([])}\n",
    "\n",
    "for row in df_participants.iterrows():\n",
    "    if row[1].Group == 'PD':\n",
    "        file_path = os.path.join(\n",
    "            '', row[1].participant_id, 'ses-{0:0>2}'.format(1), 'eeg', '')\n",
    "        tasks['local_file_path'] = np.append(\n",
    "            tasks['local_file_path'], file_path)\n",
    "        file_path = os.path.join(\n",
    "            '', row[1].participant_id, 'ses-{0:0>2}'.format(2), 'eeg', '')\n",
    "        tasks['local_file_path'] = np.append(\n",
    "            tasks['local_file_path'], file_path)\n",
    "\n",
    "        tasks['raw_data_file_name'] = np.append(\n",
    "            tasks['raw_data_file_name'], row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.set'.format(1))\n",
    "        tasks['raw_data_file_name'] = np.append(\n",
    "            tasks['raw_data_file_name'], row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.set'.format(2))\n",
    "\n",
    "        # tasks['preprocessed_one'] = np.append(tasks['preprocessed_one'],'pre_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.set'.format(1))\n",
    "        # tasks['preprocessed_one'] = np.append(tasks['preprocessed_one'],'pre_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.set'.format(2))\n",
    "\n",
    "        tasks['preprocessed_two'] = np.append(\n",
    "            tasks['preprocessed_two'], 'pre_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_double.set'.format(1))\n",
    "        tasks['preprocessed_two'] = np.append(\n",
    "            tasks['preprocessed_two'], 'pre_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_double.set'.format(2))\n",
    "\n",
    "        tasks['ERP_mat_file'] = np.append(tasks['ERP_mat_file'], 'ERP_correct_' +\n",
    "                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "        tasks['ERP_mat_file'] = np.append(tasks['ERP_mat_file'], 'ERP_correct_' +\n",
    "                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(2))\n",
    "\n",
    "        tasks['ERP_npy_file'] = np.append(tasks['ERP_npy_file'], 'ERP_correct_' +\n",
    "                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "        tasks['ERP_npy_file'] = np.append(tasks['ERP_npy_file'], 'ERP_correct_' +\n",
    "                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(2))\n",
    "\n",
    "        tasks['ERP_npy_file_with_normalization_and_baseline_correction'] = np.append(\n",
    "            tasks['ERP_npy_file_with_normalization_and_baseline_correction'], 'ERP_base_correct_normalization_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "        tasks['ERP_npy_file_with_normalization_and_baseline_correction'] = np.append(\n",
    "            tasks['ERP_npy_file_with_normalization_and_baseline_correction'], 'ERP_base_correct_normalization_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(2))\n",
    "\n",
    "        # tasks['PAC_sequences'] = np.append(tasks['PAC_sequences'],'PAC_sequences_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "        # tasks['PAC_sequences'] = np.append(tasks['PAC_sequences'],'PAC_sequences_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(2))\n",
    "\n",
    "        tasks['ERP_nobaseline_npy_file'] = np.append(\n",
    "            tasks['ERP_nobaseline_npy_file'], 'ERP_nb_correct_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "        tasks['ERP_nobaseline_npy_file'] = np.append(\n",
    "            tasks['ERP_nobaseline_npy_file'], 'ERP_nb_correct_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(2))\n",
    "\n",
    "        # tasks['PAC_sequences_v1'] = np.append(tasks['PAC_sequences_v1'], 'PAC_sequences_selected_ch_' +\n",
    "        #                                       row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "        # tasks['PAC_sequences_v1'] = np.append(tasks['PAC_sequences_v1'], 'PAC_sequences_selected_ch_' +\n",
    "        #                                       row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(2))\n",
    "\n",
    "        tasks['Cavanagh_habituation_signals'] = np.append(tasks['Cavanagh_habituation_signals'], 'Habituation_Cavanagh_Fz_ch_' +\n",
    "                                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "        tasks['Cavanagh_habituation_signals'] = np.append(tasks['Cavanagh_habituation_signals'], 'Habituation_Cavanagh_Fz_ch_' +\n",
    "                                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(2))\n",
    "\n",
    "        tasks['Limpel_Ziv_over_channels'] = np.append(tasks['Limpel_Ziv_over_channels'], 'Limpel_Ziv_over_trials_for_all_chs_v1_' +\n",
    "                                                      row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "        tasks['Limpel_Ziv_over_channels'] = np.append(tasks['Limpel_Ziv_over_channels'], 'Limpel_Ziv_over_trials_for_all_chs_v1_' +\n",
    "                                                      row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(2))\n",
    "\n",
    "        tasks['P300_over_all_channels_without_normalization'] = np.append(tasks['P300_over_all_channels_without_normalization'], 'P300_over_all_channels_' +\n",
    "                                                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "        tasks['P300_over_all_channels_without_normalization'] = np.append(tasks['P300_over_all_channels_without_normalization'], 'P300_over_all_channels_' +\n",
    "                                                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(2))\n",
    "        # tasks['PAC_dist_mean_channel'] = np.append(tasks['PAC_dist_mean_channel'],'PAC_mean_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.mat'.format(1))\n",
    "        # tasks['PAC_dist_mean_channel'] = np.append(tasks['PAC_dist_mean_channel'],'PAC_mean_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.mat'.format(2))\n",
    "\n",
    "        # tasks['Rank_Stage'] = np.append(tasks['Rank_Stage'], 'Rank_stages_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.mat'.format(1))\n",
    "        # tasks['Rank_Stage'] = np.append(tasks['Rank_Stage'], 'Rank_stages_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.mat'.format(2))\n",
    "\n",
    "        tasks['Group_file_type'] = np.append(\n",
    "            tasks['Group_file_type'], row[1].Group + '_' + row[1].sess1_Med)\n",
    "        tasks['Group_file_type'] = np.append(\n",
    "            tasks['Group_file_type'], row[1].Group + '_' + row[1].sess2_Med)\n",
    "\n",
    "    else:\n",
    "        file_path = os.path.join(\n",
    "            '', row[1].participant_id, 'ses-{0:0>2}'.format(1), 'eeg', '')\n",
    "        tasks['local_file_path'] = np.append(\n",
    "            tasks['local_file_path'], file_path)\n",
    "\n",
    "        tasks['raw_data_file_name'] = np.append(\n",
    "            tasks['raw_data_file_name'], row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.set'.format(1))\n",
    "\n",
    "        # tasks['preprocessed_one'] = np.append(tasks['preprocessed_one'],'pre_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.set'.format(1))\n",
    "\n",
    "        tasks['preprocessed_two'] = np.append(\n",
    "            tasks['preprocessed_two'], 'pre_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_double.set'.format(1))\n",
    "\n",
    "        tasks['ERP_mat_file'] = np.append(tasks['ERP_mat_file'], 'ERP_correct_' +\n",
    "                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "\n",
    "        tasks['ERP_npy_file'] = np.append(tasks['ERP_npy_file'], 'ERP_correct_' +\n",
    "                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "\n",
    "        tasks['ERP_npy_file_with_normalization_and_baseline_correction'] = np.append(\n",
    "            tasks['ERP_npy_file_with_normalization_and_baseline_correction'], 'ERP_base_correct_normalization_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "\n",
    "        tasks['ERP_nobaseline_npy_file'] = np.append(\n",
    "            tasks['ERP_nobaseline_npy_file'], 'ERP_nb_correct_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "\n",
    "        # tasks['PAC_sequences_v1'] = np.append(\n",
    "        #     tasks['PAC_sequences_v1'], 'PAC_sequence_selected_ch_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.npy'.format(1))\n",
    "\n",
    "        tasks['Cavanagh_habituation_signals'] = np.append(tasks['Cavanagh_habituation_signals'], 'Habituation_Cavanagh_Fz_ch_' +\n",
    "                                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "\n",
    "        tasks['Limpel_Ziv_over_channels'] = np.append(tasks['Limpel_Ziv_over_channels'], 'Limpel_Ziv_over_trials_for_all_chs_v1_' +\n",
    "                                                      row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "\n",
    "        tasks['P300_over_all_channels_without_normalization'] = np.append(tasks['P300_over_all_channels_without_normalization'], 'P300_over_all_channels_' +\n",
    "                                                                          row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg_db.mat'.format(1))\n",
    "        # tasks['PAC_dist_mean_channel'] = np.append(tasks['PAC_dist_mean_channel'],'PAC_mean_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.mat'.format(1))\n",
    "\n",
    "        # tasks['Rank_Stage'] = np.append(tasks['Rank_Stage'], 'Rank_stages_' + row[1].participant_id + '_ses-{0:0>2}_task-Rest_eeg.mat'.format(1))\n",
    "\n",
    "        tasks['Group_file_type'] = np.append(\n",
    "            tasks['Group_file_type'], row[1].Group)\n",
    "\n",
    "\n",
    "task_df = pd.DataFrame(tasks)\n",
    "if platform.system() == 'Linux':\n",
    "    task_df.to_csv(\n",
    "        './task_track_file_matlab_linux_double_calculation_Habituation.csv')\n",
    "else:\n",
    "    task_df.to_csv(\n",
    "        './task_track_file_matlab_windows_double_calculation_Habituation.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dbf7481e991054104c17e61eb52bd4328dee5ea57af3a8ef865b5839f725976"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('brain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
